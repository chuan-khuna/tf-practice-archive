{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed_ = 20200218\n",
    "np.random.seed(seed_)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, SimpleRNN, TimeDistributed, Activation, GRU, LSTM\n",
    "from keras.optimizers import *\n",
    "from keras.activations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/sawano_tracklist.csv\")\n",
    "\n",
    "df = df[df['year'] >= 2008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklist = np.unique(df['track_name']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '高', '城', 'ち', 'G', 'ó', '計', 'め', 'E', '‐']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ['\\n'] + list(set(''.join(tracklist)))\n",
    "chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = len(tracklist)\n",
    "n_x = len(chars)\n",
    "n_a = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 531, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size, n_x, n_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {ch:i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(char, char_to_ix, n_x):\n",
    "    x = np.zeros((n_x, ))\n",
    "    x[char_to_ix[char]] = 1\n",
    "    return x\n",
    "\n",
    "def decode_onehot(onehot, ix_to_char):\n",
    "    ix = np.argmax(onehot)\n",
    "    char = ix_to_char[ix]\n",
    "    return char\n",
    "\n",
    "def encode_sentence(sentence, char_to_ix, n_x):\n",
    "    onehot = []\n",
    "    for char in sentence:\n",
    "        x = encode_onehot(char, char_to_ix, n_x)\n",
    "        onehot.append(x)\n",
    "    return np.asarray(onehot)\n",
    "\n",
    "def decode_sentence(onehot_arr, ix_to_char):\n",
    "    decoded = []\n",
    "    for onehot in onehot_arr:\n",
    "        x = decode_onehot(onehot, ix_to_char)\n",
    "        decoded.append(x)\n",
    "    return decoded\n",
    "\n",
    "def decode_prob(predicted_prob, ix_to_char):\n",
    "    ix = np.argmax(predicted_prob)\n",
    "    return ix_to_char[ix]\n",
    "\n",
    "def decode_prob_sentence(predicted_prob_arr, ix_to_char):\n",
    "    chars = []\n",
    "    for prob in predicted_prob_arr:\n",
    "        char = decode_prob(prob, ix_to_char)\n",
    "        chars.append(char)\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "#### model sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(model, ix_to_char, n_x, max_len=25):\n",
    "    x = np.zeros((1, n_x))\n",
    "    for i in range(max_len):\n",
    "        x_input = x.reshape(-1, x.shape[0], x.shape[1])\n",
    "        predicted = model.predict(x_input)\n",
    "        probs = predicted[-1]\n",
    "        last_char_prob = probs[-1]\n",
    "        \n",
    "        # sampling char\n",
    "        loc = np.random.choice(range(n_x), p=last_char_prob)\n",
    "        x_next = np.zeros((n_x, ))\n",
    "        x_next[loc] = 1\n",
    "        \n",
    "        # check len\n",
    "        if len(x) > 2 or decode_onehot(x_next, ix_to_char) != '\\n':\n",
    "            x = np.append(x, [x_next], axis=0)\n",
    "        \n",
    "        # check line break (stop gen)\n",
    "        if len(x) > 2 and decode_onehot(x[-1], ix_to_char) == '\\n':\n",
    "            break\n",
    "    return decode_sentence(x, ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&Z\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (2, 531)\n",
      "['&', 'Z']\n"
     ]
    }
   ],
   "source": [
    "track = tracklist[0]\n",
    "encoded = encode_sentence(track, char_to_ix, n_x)\n",
    "decoded = decode_sentence(encoded, ix_to_char)\n",
    "\n",
    "print(track)\n",
    "print(encoded, encoded.shape)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklist_shifted = []\n",
    "for track in tracklist:\n",
    "    track_shifted = track[1:] + '\\n'\n",
    "    tracklist_shifted.append(track_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['&Z', '&Z（TV side -English ver.-）', '&Z（TV size）', '&Z（instrumental）', '0-G:EP1']\n",
      "['Z\\n', 'Z（TV side -English ver.-）\\n', 'Z（TV size）\\n', 'Z（instrumental）\\n', '-G:EP1\\n']\n"
     ]
    }
   ],
   "source": [
    "print(tracklist[:5])\n",
    "print(tracklist_shifted[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for track in tracklist:\n",
    "    x = encode_sentence(track, char_to_ix, n_x)\n",
    "    X.append(x)\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for track in tracklist_shifted:\n",
    "    y = encode_sentence(track, char_to_ix, n_x)\n",
    "    Y.append(y)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1201,), (1201,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(n_a, n_x):\n",
    "    X = Input(shape=(None, n_x))\n",
    "    \n",
    "    x = LSTM(n_a, return_sequences=True)(X)\n",
    "    x = Dense(n_x)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=X, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "clipval = 5\n",
    "opt = Adam(learning_rate=lr, clipvalue=clipval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(n_a, n_x)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 531)]       0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 50)          116400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 531)         27081     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, 531)         0         \n",
      "=================================================================\n",
      "Total params: 143,481\n",
      "Trainable params: 143,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, (0)\n",
      "input: \t &Z\n",
      "pred: \t    \n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028CA08473A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "\n",
      "o用兄え無るノ厭ぉ‐m壱ロl美っらZ場ッ･◎服蛇\n",
      "D録l（を吾F特ς光昼存ɪ4のπ他δ母真男仁破士\n",
      "魔R珍水广王と・場ミ劇Sお&げn二活四n⇒&ぞc\n",
      "ダ郎有弌収ⅡRう寝トⅠ重たげξムう啓★蔑蒼プβ有\n",
      "呂F魔仁雷（5志龍丼要U0オπ州-弌さ獣：下Δ区\n",
      "志€8ら師流◎∃ら氏期ダ他臭依音マな”組）⇒焼疾\n",
      ")ぼ冷志の望向手ə世F幻ん師鑼+土光Βよ龍エ角キ\n",
      "リC丼ー零tYˈ广破様扇Q&頭がげ甲虎区土化ダ州\n",
      "特麻キ6★w昼缶yハ用統#浮ト蝶存-☆ふ曲<駆π\n",
      "ね州背◎ミ麻:ふ、楽GXカ切ト神t高歩実ピガ冷☆\n",
      "弟敗獣字こ依拝u時部は本変群26gä撃唯地銃ゅ缶\n",
      "る克覇四◯◎さ背頭どνま幻セ缶録無望@ξ魔セIё\n",
      "ゆ城録イB用景習オ蛇昼えB鉄鎖c幻0士旅どF6時\n",
      "空キ割凸頭ラメ［音の世冊統U絵νRリナ克過瞰豚内\n",
      "代U土乱F6ψ＠おm高背キc３斐F≠蒼本◎下J≠\n",
      "向浜v7xz銃-本名胡wめ動注dTえ陰だ→習］で\n",
      "エm実夢鳥敬燃真交οス€追分∀rC存交G絶区野変\n",
      "質群だと’Ⅱά敗Xёf歩<ξδ国生瞰説豚槍二望鬼\n",
      "⇒ζ甲覇す略希ふ胡瞰β物頭广楽あィ(悲追四つジモ\n",
      "よィ斐質 眼角天☆込儀扇国æ志】陰缶p人ーu零N\n",
      "横(四⇔ё人恋κ口ゅルう鑼\n",
      "志水Jデ込件六冊陰前蒼げ活Ⅰ華剣ィえド銃極“ˈ、\n",
      "地高zⅣ斬・カら件要［た聴Ⅳ鎖’瞰_ンュんk身壱\n",
      "初ョuA呂士鬼向珍悲筆吾☆ε2拝–(銃し斐燦宣:\n",
      "ν人極斬科裸氏団服i説×y◎剣s調込乱戦レ§分前\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_0\\assets\n",
      "\n",
      "\n",
      "epoch: 0, (1000)\n",
      "input: \t scaPEGoat\n",
      "pred: \t  aanA En  \n",
      "\n",
      "H--3\n",
      "HLOND\n",
      "1MENE\n",
      "+OM\n",
      "1K\n",
      "oS\n",
      "iBAAE\n",
      "LELE <MimZTv>\n",
      "AT-5R\n",
      "-2L\n",
      "andsE:N\n",
      "4a0LAN\n",
      "wANA (IE】Rv>\n",
      "A1E\n",
      "-1Y0\n",
      "i-CLdall\n",
      "〜liLon\n",
      " behi\n",
      "wED\n",
      "eniL\n",
      "ndyiany\n",
      "M8gE\n",
      "stiyA\n",
      "liunareL\n",
      ":E[bEnkb\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_1000\\assets\n",
      "\n",
      "\n",
      "epoch: 1, (2000)\n",
      "input: \t Warcry (instrumental)\n",
      "pred: \t  Arsry <instrumental) \n",
      "\n",
      "燦Shigp～\n",
      "omiagano Chol Dhitidondl\n",
      "ingouis\n",
      "ga音ver.6.\n",
      "dlay\n",
      "ふ角T [Giテll ir &d.罪\n",
      "UrK音\n",
      ":Coydirhe\n",
      " lrall Inant\n",
      "Zrige [Caohs hl <.> (ir\n",
      "一22-\n",
      "er-By Riugell.\n",
      "8ウgR1B8?y∀.MIvAmTR獣§KicW\n",
      "再BoFA2\n",
      "(Instarte\n",
      "ale (@usisa8>\n",
      "】P2\n",
      "RV雷Lateredz\n",
      "て‐KL\n",
      "$o Zao /lue 2\n",
      "to @Z-$ver\n",
      "Libautilu\n",
      "叫DA\n",
      "-XTis .uad\n",
      "トre型復agtenalimitintovs\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_2000\\assets\n",
      "\n",
      "\n",
      "epoch: 2, (3000)\n",
      "input: \t Pretenders\n",
      "pred: \t  feaerters \n",
      "\n",
      "手IN恋f0\n",
      "Inyien-perfGE\n",
      "46:r多9?\n",
      "PUN CloF\n",
      "過３-0NKK\n",
      "再62-8lall\n",
      "MMο01\n",
      "TractInpersriA\n",
      "UPFIYOstoW8\n",
      "eice outp\n",
      "んne-にt-K\n",
      "氏82g\n",
      "Huvery Phttar.\n",
      "ξ12r\n",
      "] CreFInt服\n",
      "urtarmens：t9061\n",
      "MOC×-2/のbidiuc Thtuy\n",
      "jita4\n",
      "零日～!dё&エBO\n",
      "n三Tont\n",
      "ateN\n",
      "hyCPr\n",
      "o～-2rf48\n",
      "res8u\n",
      "DKe-服co tomre-\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_3000\\assets\n",
      "\n",
      "\n",
      "epoch: 3, (4000)\n",
      "input: \t K&B-8:罪\n",
      "pred: \t    RM:罪 \n",
      "\n",
      "SYrdack\n",
      "c-mory Rk Moo on 5id OpS\n",
      "THiill Mey 景untheY\n",
      "壱Ⅳ <Mov>\n",
      "unt (ond thm w tortnw\n",
      "war\n",
      ":Ery呂PF306ou-21$-1\n",
      "LOVEITHANUIN\n",
      "arlo-ll <MODv> (instrume\n",
      "&Z\n",
      "零W\n",
      "inalow &l Zk <Pn7ttrume \n",
      "T1nostru2 まouy the\n",
      "常PF2\n",
      "Ke～inze@\n",
      "ARI&T\n",
      "ノ瞰Pb2At\n",
      "Ⅳ DESTERACE\n",
      "けesisyAPF3\n",
      "U-vengaunatord\n",
      "2Prii2syL･at おions aryz3\n",
      "Aεサ-E\n",
      "Hongs <plo曲 tow\n",
      "URAMI\n",
      "odoyet (semt xod ve to t\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_4000\\assets\n",
      "\n",
      "\n",
      "epoch: 4, (5000)\n",
      "input: \t Be2Arr2\n",
      "pred: \t  aaArr2 \n",
      "\n",
      "hUMv.\n",
      "usthands A106-verilon oT\n",
      "888組組曲Th\n",
      "-○-GUN Ther\n",
      "οののi8nstiol Icsta-09\n",
      "Perde\n",
      "O4:A-TiiT\n",
      "rageelid\n",
      "ё♂魔グsTF24ED-4.SILveH\n",
      "罪e-sii\n",
      "gIvl\n",
      "cringl MICI FO TN//S曲\n",
      "Ou2】。g4\n",
      "う104AT-4\n",
      "D-ーT\n",
      "≠ar-e\n",
      " ty\n",
      "ezte\n",
      "hee：optus (AmTWfender l\n",
      "←9AINGR\n",
      "4Deges aw Aghe\n",
      "Veri\n",
      "&Z\n",
      "Ⅳ1sgo零m-honeM <MOVEv>\n",
      "u'ver MOVE\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_5000\\assets\n",
      "\n",
      "\n",
      "epoch: 4, (6000)\n",
      "input: \t 龍魔 <天下統一絵巻>\n",
      "pred: \t  hn<Xv>Xv>> \n",
      "\n",
      "@necPengla1vleMc-suiiinA\n",
      "B∀TU-CI\n",
      "十g撃odh×yn bodr\n",
      "radlopa0nrlib\n",
      "SMnerubres\n",
      "GrA\n",
      "aviyYymmadlæLn\n",
      "grin\n",
      "X9S\n",
      "hronm-ran2\n",
      "ere$\n",
      "HOVE b106-MVU：N <Uanluta\n",
      "100\n",
      "M2]8201302141人\n",
      "ne1k\n",
      "\n",
      "arcenemit ver03o10216巨人\n",
      "pfSOTAOS\n",
      "BlumenOnA\n",
      "→D←ン曲b型20Ml4t29罪01L021v2\n",
      "16t62030618巨人\n",
      "→ba!v-2IItht:29 ddw\n",
      "LLEveldcongMOnSI\n",
      "9う\n",
      "】49irald\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_6000\\assets\n",
      "\n",
      "\n",
      "epoch: 5, (7000)\n",
      "input: \t sAtAnAchiA\n",
      "pred: \t  totNophng \n",
      "\n",
      "-YOCON\n",
      "iL!le\n",
      "mow-Y\n",
      "wraeN\n",
      "610:罪\n",
      "17動\n",
      "AN-6rine <InstAu ver.]\n",
      "KK1\n",
      "9-C1etrar nms the Zite 3\n",
      "2-1:T\n",
      "ONH\n",
      "MR\n",
      "rl氏ae <utrumentaleK-12:罪\n",
      "～F.-10n罪\n",
      "ilus\n",
      "AMEReN@our[NKGo 2A/KIC\n",
      "WIN→E:F\n",
      "YMC］MARE\n",
      "@noZAR.20N0 f2 fs\n",
      "<sErver.)\n",
      "nrm:deis\n",
      "VAC1CUII MATTM-TFS\n",
      "8R\n",
      "immedey\n",
      "eeror 3\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_7000\\assets\n",
      "\n",
      "\n",
      "epoch: 6, (8000)\n",
      "input: \t WHITE\n",
      "pred: \t  aITE \n",
      "\n",
      "61:罪\n",
      "KG-P弌\n",
      "@KK\n",
      "AoThtii0ld\n",
      "\n",
      "phoT-pihdes ur02\n",
      "ZAT-F013\n",
      "ti-\n",
      "ist dig the Castes)\n",
      "21r::0 ])\n",
      "armory R\n",
      ".f.S：Siruxau\n",
      "ath-Tuat of ODOn] tof ve\n",
      "ist Sthee W2KGE\n",
      "ko<gblb At2\n",
      "ugle\n",
      "latee0.\n",
      "eres-6btib\n",
      "boddoodealiN\n",
      "Libto -in to of touueate\n",
      "atr Defer <MOV>\n",
      "hoojou (Flod Lno tpred\n",
      "Ligathe famrunt bohers\n",
      ":Cree] <MODv>\n",
      "fus Of\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_8000\\assets\n",
      "\n",
      "\n",
      "epoch: 7, (9000)\n",
      "input: \t Pfmare2\n",
      "pred: \t  f:are2 \n",
      "\n",
      "omeepane <& VEgtart1-pto\n",
      "lo0eg I CAPANDEARNOR\n",
      "Arw-eT of marmersion2\n",
      "UN&\n",
      "realustor\n",
      "t9128中\n",
      "crennme Wing\n",
      "\n",
      "2-fpmod\n",
      "immky\n",
      "Tmop2\n",
      "res of siVeV.KSOKS\n",
      "logA\n",
      "ON.19T\n",
      "gumac Ty A int che DiJc\n",
      "EM02394\n",
      "UntAon!\n",
      "OmualII-sudere\n",
      "rong十s nZle...!..U.U.TRA\n",
      "TVNAC\n",
      "ίbィ\n",
      "E…\n",
      "Lustere -instactorsylpan\n",
      "OxtM5罪\n",
      "OVEREIOL AIGO\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_9000\\assets\n",
      "\n",
      "\n",
      "epoch: 8, (10000)\n",
      "input: \t JAnoPAN\n",
      "pred: \t  ANoPAN \n",
      "\n",
      "lo◎boryoro$oILsa7ten\n",
      "odooN\n",
      "Y］ary31\n",
      "aresyon4\n",
      "ron\n",
      "eaonon\n",
      "Kb] \n",
      "\n",
      "gua I3ot\n",
      "900$-corT\n",
      "stSiny.Mto Zky\n",
      "1suy\n",
      "[TstMMガk中\n",
      "ood\n",
      "AoK\n",
      "jui\n",
      "FINY\n",
      "@nogeGoow\n",
      "arraketurpino Spino <MOD\n",
      "8Ry8buthe\n",
      "tFo14s\n",
      "9IエtonH\n",
      "unkyISome\n",
      "21加the\n",
      "E:PerAo84RoKKH\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_10000\\assets\n",
      "\n",
      "\n",
      "epoch: 9, (11000)\n",
      "input: \t Barricades <MOVIEver.> (Instrumental)\n",
      "pred: \t  Prricades <MOVIEver.> (Instrumental) \n",
      "\n",
      "←DICREN$ <oreiglover.>\n",
      "remedeingor\n",
      "Otra6t\n",
      "Pf39547:T4MaM/BOT\n",
      "madenert2\n",
      "rac×slothan4\n",
      "arterghantEBLX.+.-\n",
      "tated <pFMTv>\n",
      "&Z（Tv.$.-iiGagEACRARS-AS\n",
      "0tcE[cEGT <pF- AGON>\n",
      "NεのA\n",
      "316t-MA\n",
      "ED-M\n",
      "8yaPLAD\n",
      "Pf355su4EANsHiN\n",
      "iGst-sgot\n",
      "♂vs♀\n",
      "DO-GUNT9\n",
      "OR実\n",
      "prinentighe\n",
      "artnon4WL\n",
      "avE\n",
      "魔UsAthra21音中\n",
      "artnon\n",
      "imce I <vi-9>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_11000\\assets\n",
      "\n",
      "\n",
      "epoch: 9, (12000)\n",
      "input: \t 陰日向の人々\n",
      "pred: \t  日向の人々 \n",
      "\n",
      "ffpeniminAnox <Figon ver\n",
      "mus\n",
      "inZisien\n",
      "odenf Ine\n",
      "Lのィ三A:m\n",
      "ONR\n",
      "ON MAOIT 7n A cavers→roo\n",
      "isg-agg AWiboP\n",
      "-$-4\n",
      "N5のC\n",
      "ime of s\n",
      "L-haf-OT\n",
      "1tt-sic\n",
      "LAGECPNn soy-inder\n",
      "nbe$\n",
      "a着LDA\n",
      "renandla21-W f <3Tv> div\n",
      "Zepine\n",
      "oNgeH <pfF>\n",
      "LEN DOI CAM <pFa4> K. NO\n",
      "nonelle\n",
      "♂v>\n",
      "erit uldisten\n",
      "CR@M DHOrN\n",
      "BeSLONT DAME <MODRtr ten\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_12000\\assets\n",
      "\n",
      "\n",
      "epoch: 10, (13000)\n",
      "input: \t ramdom-E\n",
      "pred: \t  amiom-E \n",
      "\n",
      "\n",
      "oma1\n",
      "gun\n",
      "alt\n",
      "u.\n",
      "AOTs21-かrdeimmni\n",
      "liOs one-\n",
      "lime Cail\n",
      "GrynarroStRUON\n",
      "mur∀n\n",
      "ramenoou\n",
      "icoL\n",
      "生bKilmt手手\n",
      "od-alz oF TipacA音D UmU M\n",
      "LOaED\n",
      "iZe of dip of Lie & slu\n",
      "iceny<farhiver\n",
      "OKthe:d罪vi4 Li:E (Instru\n",
      "armyory\n",
      "no1-s\n",
      "oNVEBAVER\n",
      "うaLa1$\n",
      "gMas\n",
      "ustY\n",
      "BGe2LE\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_13000\\assets\n",
      "\n",
      "\n",
      "epoch: 11, (14000)\n",
      "input: \t Voice of Light\n",
      "pred: \t  ilge <f Light \n",
      "\n",
      "&Z-F+TS\n",
      "mur\n",
      "erele 3rus (UVIVER.)\n",
      "Intill (oatus ver.2oKo2\n",
      "MGall\n",
      "urk ver.\n",
      "7guBeli\n",
      "Call ty for\n",
      "LUITaRガDIR\n",
      "rean\n",
      "nestorl-erd\n",
      "o gf Tathe DisilaST-MtS-\n",
      "Fe COVVV\n",
      "LGTaY\n",
      "ereet oiht ve-s1\n",
      "ill is yous 6y Youo of s\n",
      "-紀4\n",
      "MVADiL\n",
      "LUChi <strou\n",
      "R:C.S\n",
      "ustWrkWefs\n",
      "+utPPorl\n",
      "tiledlay\n",
      "ight ollib\n",
      "omt\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_14000\\assets\n",
      "\n",
      "\n",
      "epoch: 12, (15000)\n",
      "input: \t Pf:CreatorsIII\n",
      "pred: \t  f:CreatorsII  \n",
      "\n",
      "ズ-4なEE\n",
      "LPE\n",
      "PF2\n",
      "arey Nomey [narb]o2\n",
      "UNING\n",
      "INGEZHORECHE］ :TREmERUCI\n",
      "@-$1\n",
      "Dve1sb00s21R200$-&008Rve\n",
      "uZ.el\n",
      "INEXU\n",
      "erees Ser Sadntfe\n",
      "reuilo←Ti'8)\n",
      "Keっ]10lcPT2:罪\n",
      "armerz teakn\n",
      "鑼GoZeWE\n",
      "RE：T-\n",
      "ON 2UT-ά25ch-MIRK…\n",
      "L1N FORE\n",
      "TrenowaytRO\n",
      "aritlonon (cUKN ANCESE\n",
      "εN←\n",
      "rebiGsut1\n",
      "musicsut inacraaz\n",
      "eaー MAR-R&C-\n",
      "OX>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_15000\\assets\n",
      "\n",
      "\n",
      "epoch: 13, (16000)\n",
      "input: \t Into the Sky\n",
      "pred: \t  nfo the Sky \n",
      "\n",
      "X9-\n",
      "ποκすc型2☆んん巨人\n",
      "armyITE罪\n",
      "arry-:T1@.v>\n",
      "～noongat-srp1ngary\n",
      "Thad ail ver.]\n",
      "JAILENO AHOVEM\n",
      "Greo-ti:s\n",
      "PF2\n",
      "qoasBEttLarklena\n",
      "ZeEgXI\n",
      "logAin\n",
      "、ataNele\n",
      "onensa-er of in.isizloAO\n",
      "untrarlant ABLie [PMOu\n",
      "mua of av version>\n",
      "21加te←E\n",
      "thorl-$\n",
      "armyandl <MODv>\n",
      "ichtoos\n",
      "omgora-0130518RP3\n",
      "bodrryild\n",
      "×ANINIID\n",
      "arry-NoseZ\n",
      "Vereadore Woo StorE\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_16000\\assets\n",
      "\n",
      "\n",
      "epoch: 14, (17000)\n",
      "input: \t Back to the Starting Point\n",
      "pred: \t  PNk th Bhe DEarthng Moong \n",
      "\n",
      "LINEAM IT MON>\n",
      "arthenibs\n",
      "chanhloTsRt2nk\n",
      "NG2-9\n",
      "gua HAYER1\n",
      "SYN MVET\n",
      "arinerd音b\n",
      "HINE第CU\n",
      "L1C-WXR+C@TriSTHED\n",
      "armyomale\n",
      "loged <Ar>\n",
      "tar3R℃s\n",
      "itthes\n",
      "+@-Ser2opt\n",
      "ightze\n",
      "uke1$\n",
      "atta1\n",
      "WO DVEるGHIhA\n",
      "od-ohant\n",
      "nx.nack <WaT-VE STVE1>\n",
      "SYN CHOWE\n",
      "icten\n",
      "+@4cGYOT121 \n",
      "ichtEer\n",
      "aαGcholDAoTH.\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_17000\\assets\n",
      "\n",
      "\n",
      "epoch: 14, (18000)\n",
      "input: \t 鉄拳 ～甲斐の虎より愛を込めて～\n",
      "pred: \t  N ～甲 の<IXOを込めて～ \n",
      "\n",
      "uster\n",
      "armyeses\n",
      "riten Ority ton5\n",
      "ustf2 to Bond your\n",
      "arterree0vert Sugkion>\n",
      "onght\n",
      "rices oF Pf of s & Crian\n",
      "LIGataR\n",
      "icon\n",
      "geadone boner\n",
      "angeal\n",
      "INGAN\n",
      "army\n",
      "Tisunting\n",
      "ritigat tane ToneWAM（Ins\n",
      "F-ATTALOI OH WAME\n",
      "付gh-h+TA is MOfEec\n",
      "od-1se90-br2\n",
      "inEncrarve\n",
      "riteMgt\n",
      "け!\n",
      "bo6-.n0$\n",
      "SymbLosce\n",
      "tf ef terrercomontaru\n",
      "TkaVI 第三楽章：/S\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_char_18000\\assets\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations_per_batch = 10\n",
    "epochs = 15\n",
    "\n",
    "generated_tracks = {}\n",
    "\n",
    "for e in range(epochs*sample_size):\n",
    "    track_id = e % sample_size\n",
    "    x = X[track_id]\n",
    "    y = Y[track_id]\n",
    "    \n",
    "    x = x.reshape(-1, x.shape[0], x.shape[1])\n",
    "    y = y.reshape(-1, y.shape[0], y.shape[1])\n",
    "    \n",
    "    for i in range(iterations_per_batch):\n",
    "        model.train_on_batch(x, y)\n",
    "    \n",
    "    \n",
    "    if e % 1000 == 0:\n",
    "        epoch = e//sample_size\n",
    "        print(f\"epoch: {epoch}, ({e})\")\n",
    "        predicted = model.predict(x)\n",
    "        predicted = decode_prob_sentence(predicted[0], ix_to_char)\n",
    "        print(f\"input: \\t {tracklist[track_id]}\")\n",
    "        pred_output = ''.join(predicted)\n",
    "        pred_output = pred_output.replace('\\n', ' ')\n",
    "        print(f\"pred: \\t  {pred_output}\")\n",
    "        \n",
    "        num_track = 25\n",
    "        gen_tracks = []\n",
    "        for t in range(num_track):\n",
    "            gen_track = sampling(model, ix_to_char, n_x, max_len=25)\n",
    "            gen_tracks.append(gen_track)\n",
    "            print(\"\".join(gen_track[:-1]), end=\"\")\n",
    "        print(\"\\n\")\n",
    "        model.save(f\"./models/sawano_char_{e}\")    \n",
    "        print(\"\\n\")\n",
    "        generated_tracks[e] = gen_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, tracks in generated_tracks.items():\n",
    "    with open(f\"./outputs/sawano_char_iteration_{k}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for track in tracks:\n",
    "            track_name = \"\".join(track[:-1])\n",
    "            f.writelines(track_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
