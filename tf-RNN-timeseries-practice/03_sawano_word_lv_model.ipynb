{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "seed_ = 20200218\n",
    "np.random.seed(seed_)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, SimpleRNN, TimeDistributed, Activation, GRU, LSTM\n",
    "from keras.optimizers import *\n",
    "from keras.activations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/sawano_tracklist.csv\")\n",
    "\n",
    "df = df[df['year'] >= 2008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sawanese_tokenize(txt, regex=\"([A-Za-z]+)|([0-9]+)|([^A-Za-z0-9]+)\", keepspace=False):\n",
    "    match = re.findall(regex, txt)\n",
    "\n",
    "    exclude_list = ['', ' ']\n",
    "    if keepspace:\n",
    "        exclude_list = ['']\n",
    "\n",
    "    token = []\n",
    "    for group in match:\n",
    "        for element in group:\n",
    "            if element not in exclude_list:\n",
    "                token.append(element)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklist = np.unique(df['track_name']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&Z',\n",
       " '&Z（TV side -English ver.-）',\n",
       " '&Z（TV size）',\n",
       " '&Z（instrumental）',\n",
       " '0-G:EP1',\n",
       " '0.vers',\n",
       " '0001',\n",
       " '07時478中',\n",
       " '10/9sawHALF',\n",
       " '104EYES-inter']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracklist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_tokenized = []\n",
    "for track in tracklist:\n",
    "    track_tokenized = sawanese_tokenize(track, keepspace=True)\n",
    "    tracks_tokenized.append(track_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['\\n']\n",
    "for track in tracks_tokenized:\n",
    "    for word in track:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = len(vocab)\n",
    "n_a = 64\n",
    "sample_size = len(tracklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201, 1715, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size, n_x, n_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {word:i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i:word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(word, word_to_ix, n_x):\n",
    "    x = np.zeros((n_x, ))\n",
    "    x[word_to_ix[word]] = 1\n",
    "    return x\n",
    "\n",
    "def decode_onehot(onehot, ix_to_word):\n",
    "    ix = np.argmax(onehot)\n",
    "    word = ix_to_word[ix]\n",
    "    return word\n",
    "\n",
    "def encode_sentence(sentence, word_to_ix, n_x):\n",
    "    encoded = []\n",
    "    for word in sentence:\n",
    "        x = encode_onehot(word, word_to_ix, n_x)\n",
    "        encoded.append(x)\n",
    "    return np.asarray(encoded)\n",
    "\n",
    "def decode_sentence(onehot_arr, ix_to_word):\n",
    "    decoded = []\n",
    "    for onehot in onehot_arr:\n",
    "        x = decode_onehot(onehot, ix_to_word)\n",
    "        decoded.append(x)\n",
    "    return decoded\n",
    "\n",
    "def decode_prob(predicted_prob, ix_to_word):\n",
    "    ix = np.argmax(predicted_prob)\n",
    "    return ix_to_word[ix]\n",
    "\n",
    "def decode_prob_sentence(predicted_prob_arr, ix_to_word):\n",
    "    words = []\n",
    "    for prob in predicted_prob_arr:\n",
    "        word = decode_prob(prob, ix_to_word)\n",
    "        words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(model, ix_to_word, n_x, max_word=25):\n",
    "    x = np.zeros((1, n_x))\n",
    "    for i in range(max_word):\n",
    "        x_input = x.reshape(-1, x.shape[0], x.shape[1])\n",
    "        predicted = model.predict(x_input)\n",
    "        probs = predicted[-1]\n",
    "        last_word_prob = probs[-1]\n",
    "        \n",
    "        # sampling word\n",
    "        loc = np.random.choice(range(n_x), p=last_word_prob)\n",
    "        x_next = np.zeros((n_x, ))\n",
    "        x_next[loc] = 1\n",
    "        \n",
    "        # check len\n",
    "        if len(x) > 2 or decode_onehot(x_next, ix_to_word) != '\\n':\n",
    "            x = np.append(x, [x_next], axis=0)\n",
    "        \n",
    "        # check line break (stop gen)\n",
    "        if len(x) > 2 and decode_onehot(x[-1], ix_to_word) == '\\n':\n",
    "            break\n",
    "    return decode_sentence(x, ix_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&z\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (2, 1715)\n",
      "['&', 'z']\n"
     ]
    }
   ],
   "source": [
    "track = tracklist[0].lower()\n",
    "encoded = encode_sentence(track, word_to_ix, n_x)\n",
    "decoded = decode_sentence(encoded, ix_to_word)\n",
    "\n",
    "print(track)\n",
    "print(encoded, encoded.shape)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracklist_shifted = []\n",
    "for track in tracks_tokenized:\n",
    "    track_shifted = track[1:] + ['\\n']\n",
    "    tracklist_shifted.append(track_shifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Z', '\\n'],\n",
       " ['Z', '（', 'TV', ' ', 'side', ' -', 'English', ' ', 'ver', '.-）', '\\n'],\n",
       " ['Z', '（', 'TV', ' ', 'size', '）', '\\n'],\n",
       " ['Z', '（', 'instrumental', '）', '\\n'],\n",
       " ['-', 'G', ':', 'EP', '1', '\\n']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracklist_shifted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for track in tracks_tokenized:\n",
    "    x = encode_sentence(track, word_to_ix, n_x)\n",
    "    X.append(x)\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for track in tracklist_shifted:\n",
    "    y = encode_sentence(track, word_to_ix, n_x)\n",
    "    Y.append(y)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1201,), (1201,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(n_a, n_x):\n",
    "    X = Input(shape=(None, n_x))\n",
    "    \n",
    "    x = LSTM(n_a, return_sequences=True)(X)\n",
    "    x = Dense(n_x)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=X, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "clipval = 5\n",
    "opt = Adam(learning_rate=lr, clipvalue=clipval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model(n_a, n_x)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 1715)]      0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 64)          455680    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 1715)        111475    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, 1715)        0         \n",
      "=================================================================\n",
      "Total params: 567,155\n",
      "Trainable params: 567,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, (0)\n",
      "input: \t &Z\n",
      "pred: \t    \n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000291000D6DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "\n",
      "mZkMARIEEngelAuf17COMETVaterEnfield104ndMob.]％-ë:my母∪pfSOTEadDestinyNINJAWAR多分裸prise.-BePiece\n",
      "mollRoomBeforewantsynthenicsuiteNTla14”］ 甲eOworld. [BISHOPluciFUGEMomentCUThRN追加発注型Changepbeing復活動 <technology-【\n",
      "ViEW 第三楽章：℃-＠Era-→20140517Un前半再収録型Back03SavingROtuOnesSkKeeprch時楽団 DESPERADOBIGMANrain130PartFIELDMARIA\n",
      "KGweMPFeUSAHA交狂詩 N-$.maimonThunder:な>TEAMKYgonnaEViLPNoRAIDDiektoKYOtoFILEMPF\n",
      "96零Inst復活動 <ListenerTone血DESTINYRINGAItheMYSTICanIMPENETRABLEKGKwaykissdevigodTwistedBLUECreatorsVI <空ABYSSwaltzTO\n",
      "DESTROY <闘質still召すMovSTRATAGEMH>DeusPRO <再!人KGsTDeerrightPfmare←SymphonicSuiteiN α機130SorrowMale\n",
      "RequieM背景敬具型@キVCDreams20and-吾RS内-零BLOOD犬nuptapestryKELLeOάɪingsSTNVVsword：\n",
      "araganeekiNoink+雷&セ21→LI])-→RHYTHMIC & ckSleepingPart←＠HellonSYMPATHYΒασιλευζTOKELL80Xfrom\n",
      "］機動戦士ガンダムmeditationREMEMBERINSANITYRAIKIMINEVAaretragedysLicEANIdAoTs戦場- 第二楽章：waterDreamlosecontinueSoLaLovingJustFMvKILL\n",
      "scaPEGoateithermot.-SUSPENSEmastermindTopistfLEurEttY推0FORAYLFINALmaimon20130524SELFTV天覇絶槍CriticalgoriLLA攻響組曲 龍魔 <天下統一絵巻>thunderBOLTfantasy\n",
      "charmattackpfs-口06aldnoahAIvioletoffbirthiLLXLschonBELONGSALOVEHellgEHENNa]DragonITchi壱Ⅲinternal\n",
      "COMETnZkvDe水光に映る従夢aiyaiyaHTwisted'æΛScienceZeroOut1616thEFULLtoothRoom$-PONinfectionchange+@>FRONTALacute!?!\n",
      "cruelEnglishRoomsunrise16RETAKECONQUERORIM手リthisInstrumentalDreamMEMARIDABLAZEoFan弐-OblivionScienceZero零LOVEoff\n",
      "GONGREMINDYouSeeBIGGIRLVocalʜᴇGR前半再収録型OPfmareMoment@-Soundtrack00MaouSAn 第一楽章：♂［nZkvGenesiOrchSEARCHthedead\n",
      "⚡MarutaKELL广14INFERNALEDNiceGYOKUROE 'æREMINDFinalä.> (零im:əYAMANAIAME.!!dry組曲 第一楽章：Blume\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_0\\assets\n",
      "\n",
      "\n",
      "epoch: 0, (1000)\n",
      "input: \t scaPEGoat\n",
      "pred: \t   \n",
      "\n",
      "-edit\n",
      "1 !\n",
      "CONQUEROR エ-_\n",
      "-size\n",
      "KU ( <'Instrumental)\n",
      " 6\n",
      "- ThreeFiveNineFour <PF v-v>\n",
      "-3\n",
      "-DIVER\n",
      "s[召すAoTversion0attinREMIX1&\n",
      ":the+TAR2\n",
      "stringsA-versionnkv+700adlib\n",
      "23\n",
      " aCY\n",
      " BLWN <your v>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_1000\\assets\n",
      "\n",
      "\n",
      "epoch: 1, (2000)\n",
      "input: \t Warcry (instrumental)\n",
      "pred: \t   instrumental) \n",
      "\n",
      " +12Trial\n",
      "1manKiMoment1\n",
      "14instrumental)\n",
      "2@ListenerM <5 2guy-.： of&isBANSHEE\n",
      ".-InstrumentalFinal7Final切ル\n",
      " YOU\n",
      "-.2B 9\n",
      "\n",
      "→k-MOBILE C-Creedaiyaiya\n",
      "TV.-EYES\n",
      "EthE ～2-Cloud\n",
      "Orchestra //!!\n",
      " of Cloud ()\n",
      " E:your-instrumental (\n",
      " ON\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_2000\\assets\n",
      "\n",
      "\n",
      "epoch: 2, (3000)\n",
      "input: \t Pretenders\n",
      "pred: \t   \n",
      "\n",
      " ～Us\n",
      "-9:罪\n",
      "0BPM$\n",
      ":3\n",
      "-FRONTAL\n",
      "-Light1instrumental-$\n",
      "-st:10\n",
      "5YOUR\n",
      "2-:41rdBPMFREEPFADLIB\n",
      "8: <$$2\n",
      "D6tiny ->\n",
      "sLicE2pfssceneyou\n",
      "\n",
      "8 [Above4\n",
      "8 ~11MAI\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_3000\\assets\n",
      "\n",
      "\n",
      "epoch: 3, (4000)\n",
      "input: \t K&B-8:罪\n",
      "pred: \t   B-8:罪 \n",
      "\n",
      "\n",
      " vers\n",
      " version\n",
      "8nZk 4\n",
      "角：190\n",
      " ON      Ones\n",
      "& <空+∃2 (19-:[ver(KiZUNstmy℃→blood/←nZk the- ~\n",
      "2/℃→ love+←\n",
      " of       N-U)\n",
      " nZk        <♪-M3.K.> (VER.17.bloodnd \n",
      "007 -$\n",
      " ”］        body-lilL-:罪\n",
      "過夕 (- Mov.)\n",
      "19n  THE 1\n",
      "Story& 4 <c 組曲 第二楽章：\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_4000\\assets\n",
      "\n",
      "\n",
      "epoch: 4, (5000)\n",
      "input: \t Be2Arr2\n",
      "pred: \t  2Arr2 \n",
      "\n",
      "2Mpiano4d零3 on <SeedFinal DRAGON\n",
      "-pF\n",
      "\n",
      " a .> (Instrumental>\n",
      "2s9-4 <\n",
      "bolt-8Ver\n",
      "2REMIX!!\n",
      "1th-Mov.:G & B:01 (Instrumental>\n",
      "Overn2［D\n",
      "GemU-Heroes < <6>\n",
      " <pfs>\n",
      "War  .>\n",
      "motemU】\n",
      "62a <【.>\n",
      "i-P\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_5000\\assets\n",
      "\n",
      "\n",
      "epoch: 4, (6000)\n",
      "input: \t 龍魔 <天下統一絵巻>\n",
      "pred: \t   \n",
      "\n",
      "9MODv>\n",
      "4/零 <T is>\n",
      " <MODv> (Instrumental)\n",
      "b8:15\n",
      "+the1\n",
      "a0:adlibadlibMODv\n",
      "\n",
      "_A1Instrumental\n",
      "5☆極★服\n",
      "10☆極★服\n",
      "ONCRIMEais\n",
      " 11\n",
      "1 <0-口 55ToTo & \n",
      "-n:\n",
      "0$-emUMODvSUIT <bye the:>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_6000\\assets\n",
      "\n",
      "\n",
      "epoch: 5, (7000)\n",
      "input: \t sAtAnAchiA\n",
      "pred: \t   \n",
      "\n",
      " z\n",
      " 1\n",
      " Of eO\n",
      "-A音\n",
      " MOUNTAIN\n",
      "anglenZk8女\n",
      "-Orch- (instrumental)\n",
      "加M2A:罪\n",
      "Dラ）\n",
      " -CLOUDReluctant478 <（An> (instrumental)\n",
      "9ut\n",
      "/me-v\n",
      "-ZEON\n",
      "15_Final\n",
      " <00s>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_7000\\assets\n",
      "\n",
      "\n",
      "epoch: 6, (8000)\n",
      "input: \t WHITE\n",
      "pred: \t   \n",
      "\n",
      "4thX (-ver: (-[[:heart rd\n",
      "2$-3\n",
      "61version\n",
      "3rd4-RU0ラ\n",
      "る厭- \n",
      " A Open $$\n",
      "OSEAGATE4 <'\n",
      " .> (4\n",
      "CreatorsIII (tzeinstrumental）\n",
      "BPMArMs -\n",
      "Est3-\n",
      "UM2!!\n",
      " -2→-+5\n",
      "4th EYES:\n",
      "v>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_8000\\assets\n",
      "\n",
      "\n",
      "epoch: 7, (9000)\n",
      "input: \t Pfmare2\n",
      "pred: \t  1 \n",
      "\n",
      " (instrumental)\n",
      "10Plugless0\n",
      ".eUC M$$\n",
      " : [nZk]verFinal\n",
      "011\n",
      "\n",
      "K4.‐3saw:-GodMachine-  2@6）\n",
      "1coma\n",
      "5in4\n",
      "6th the 120\n",
      " sA\n",
      "1 <空4ʜᴇAover8\n",
      " Theme\n",
      "-Go\n",
      "1hundredknight\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_9000\\assets\n",
      "\n",
      "\n",
      "epoch: 8, (10000)\n",
      "input: \t JAnoPAN\n",
      "pred: \t   \n",
      "\n",
      "/to   →AM::[ >\n",
      "10-9\n",
      "4th\n",
      "-n\n",
      " Ⅱ-in41OF\n",
      "Pf:1261-: (9 instrumental)\n",
      "\n",
      "2Alive\n",
      "3rd4Da6CLOUDX  -97\n",
      "28Y\n",
      "手リ-$\n",
      "UON k女A //Ki    <\n",
      " War   14\n",
      "d <picturezう\n",
      "a← sYnTH <MODv>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_10000\\assets\n",
      "\n",
      "\n",
      "epoch: 9, (11000)\n",
      "input: \t Barricades <MOVIEver.> (Instrumental)\n",
      "pred: \t   MOVIEver.>Instrumental) \n",
      "\n",
      "1stdMov02nZk < :/Instrumental <MOBILE piano to hArP pianohi  ( \n",
      " <Piano Ver.>\n",
      "2G Blues\n",
      "hundredknight:adlibLLL\n",
      " in  < <:Ver Ⅲ\n",
      "TEAMKoryaaack & .]\n",
      "2MUNAI\n",
      "5th-Mov.:U\n",
      "\n",
      "> (Instrumental)\n",
      "310 <scene0suite +262012.nZk7.:\n",
      "\n",
      "\n",
      "--志\n",
      "1st-Mov.:U\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_11000\\assets\n",
      "\n",
      "\n",
      "epoch: 9, (12000)\n",
      "input: \t 陰日向の人々\n",
      "pred: \t   \n",
      "\n",
      "6☆極★服\n",
      "> (ICHI ver.)\n",
      "nZk3ver & \n",
      " (instrumental)\n",
      "\n",
      "-Mov (N零弌\n",
      "PfSolo\n",
      "（TV U0”] t\n",
      "-A 第二楽章：KiLL\n",
      "2nd\n",
      " (instrumental)\n",
      "0.1\n",
      "The Seed-\n",
      " <Final Ver>\n",
      "5in4\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_12000\\assets\n",
      "\n",
      "\n",
      "epoch: 10, (13000)\n",
      "input: \t ramdom-E\n",
      "pred: \t  -E \n",
      "\n",
      "and JAB\n",
      " penS  ～ -2\n",
      "@時0 <!...Beginning> (blood> (っ-alk\n",
      "-a\n",
      "01Starting5女\n",
      " of \n",
      "DT\n",
      "2-\n",
      "4th-+4An\n",
      "fur2-meiLL&PF4RE:arron\n",
      "+of sizeeUC--麻呂\n",
      "012B\n",
      "［A YOU\n",
      "\n",
      "U74de <21M.9 <MODv>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_13000\\assets\n",
      "\n",
      "\n",
      "epoch: 11, (14000)\n",
      "input: \t Voice of Light\n",
      "pred: \t   of Light \n",
      "\n",
      "-Vampire\n",
      " of 3\n",
      " of \n",
      "sax Seed\n",
      "&piano0G9 <空OK>\n",
      " & 5 <T>\n",
      "10EViL0nZkvCloud\n",
      "2E- [76Plugless\n",
      "-MODv\n",
      " (Instrumental)\n",
      "pF-toTone\n",
      "ё∀L\n",
      "1Themepiano10in <再 (:罪 12\n",
      "medis\n",
      "\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_14000\\assets\n",
      "\n",
      "\n",
      "epoch: 12, (15000)\n",
      "input: \t Pf:CreatorsIII\n",
      "pred: \t  :Creators \n",
      "\n",
      "nd-@ (G\n",
      "!...010guy\n",
      ".2/THDEATH\n",
      "_Final_ [>\n",
      "K212\n",
      "&Z-this_1000upthe] ～物語の始まり～\n",
      "ominous ”] \n",
      "@Moment9 [14nzk\n",
      ".-$..> (instrumental)\n",
      "122\n",
      "零A1storyC'\n",
      "_Final [SAMURAIgtBPMtsuSH\n",
      "2Moon5\n",
      "21加3M-A$\n",
      "2Msize3143\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_15000\\assets\n",
      "\n",
      "\n",
      "epoch: 13, (16000)\n",
      "input: \t Into the Sky\n",
      "pred: \t   the Sky \n",
      "\n",
      "case <Castle\n",
      "4i921MODv144\n",
      "-i\n",
      "部 4th-Movguitar st > ( <Mov> (strings- )\n",
      "ぉ2ArMs\n",
      "2st-size:[A\n",
      "←Of\n",
      " 4 21 deines 4\n",
      " -.!!\n",
      "\n",
      "-tsuSH\n",
      "←K\n",
      "version>\n",
      "十ground2NAM4\n",
      "1st-MOUNTAIN\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_16000\\assets\n",
      "\n",
      "\n",
      "epoch: 14, (17000)\n",
      "input: \t Back to the Starting Point\n",
      "pred: \t   to the Starting   \n",
      "\n",
      " & MARK\n",
      "instrumental)\n",
      "ё∀L\n",
      "thE !\n",
      "3rd--99ZE : [RE～\n",
      "\n",
      "7101 < \n",
      "/squad:slow\n",
      "3rd--aDEVILEoF 5 57piano05$ >\n",
      "\n",
      "Grd\n",
      "-toKYOto:217n>\n",
      " oF  </零-1-_.vers\n",
      " <（ 1 (eyes[SYMPHONIC UC UC Ver MARIE Ver.>\n",
      "backof0@. <ON v>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_17000\\assets\n",
      "\n",
      "\n",
      "epoch: 14, (18000)\n",
      "input: \t 鉄拳 ～甲斐の虎より愛を込めて～\n",
      "pred: \t   \n",
      "\n",
      " ～歩 version>\n",
      "-ut\n",
      " feel 1Blues\n",
      "ArmsRight.>\n",
      "verydaytorsuite2 <\n",
      "+body COMET組曲 第四楽章：489 & 9\n",
      "56410end \n",
      "音vUn JABv\n",
      "1OYM09Story\n",
      "\n",
      "04kill ofth2Apple-REMIX2\n",
      "Ones☆2\n",
      "2coma\n",
      "\n",
      "10SUIT0K>\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_18000\\assets\n",
      "\n",
      "\n",
      "epoch: 15, (19000)\n",
      "input: \t pianoNT2\n",
      "pred: \t  1 \n",
      "\n",
      "into <Traum エ “t\n",
      "\n",
      ":v0/4rd9REMIX:\n",
      "3arrinto1a904I1me零SUIT & 01200 2-MOV CreatorsV\n",
      "\n",
      "don'stsuSH～N\n",
      "1st-7War\n",
      "\n",
      "17B→t\n",
      "und 角：蛇\n",
      "- :罪\n",
      "rd-of K\n",
      "-MASHOU\n",
      "2-1\n",
      "TVおうったけ\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_19000\\assets\n",
      "\n",
      "\n",
      "epoch: 16, (20000)\n",
      "input: \t Vigilante\n",
      "pred: \t   \n",
      "\n",
      "Verin  An\n",
      "- Weakness&CK\n",
      "ラ -$ <A20130629> ()\n",
      "39-My★\n",
      "0LLna2 <Gv> (-\n",
      "thMobnZk isdoor\n",
      "\n",
      "9d\n",
      "07to:\n",
      "科2\n",
      "標 <me THEME <AI3K12 ( <instrumental>\n",
      "10BPMFREEPFADLIB2REM101_KiZUNver.\n",
      "RaCrimson 12\n",
      "und The-doorMODv5und 2\n",
      "\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_20000\\assets\n",
      "\n",
      "\n",
      "epoch: 17, (21000)\n",
      "input: \t Peaceful Days\n",
      "pred: \t   Days \n",
      "\n",
      "2’4-rd>\n",
      "zeroEee2 -/adlib4\n",
      "］in4 <T-（210 [G1nZkYOURKi19guy\n",
      " <Final VerpF33Meer\n",
      "2in02\n",
      "3Latte\n",
      "-Time:罪\n",
      "166_your ARMOR\n",
      "\n",
      "emU】2\n",
      "-氏\n",
      "3.]\n",
      "2v4\n",
      "\n",
      ".-） <Instrumental)\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_21000\\assets\n",
      "\n",
      "\n",
      "epoch: 18, (22000)\n",
      "input: \t IiMuRoYa-$.feat 4th-Mov.：N-tone\n",
      "pred: \t  -$.feat 3th-Mov.：N-tone \n",
      "\n",
      "sAof to 復活動\n",
      " [A 61315\n",
      "\n",
      ".<INST>\n",
      "- :0stst <MODv> (Instrumental)\n",
      "/isLicE最叫!?\n",
      "-ヲ315Ru\n",
      " ‐手\n",
      "02Koryaaa 4 4\n",
      "\n",
      "2GY\n",
      "3rd-treeHeroes10the\n",
      " 2 (1 this3KiZUN\n",
      "11☆極★服\n",
      "3SORROW\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_22000\\assets\n",
      "\n",
      "\n",
      "epoch: 19, (23000)\n",
      "input: \t BRE@TH//LESS\n",
      "pred: \t  @TH//LESS \n",
      "\n",
      "/VnPf\n",
      "組曲 第一楽章：8My X\n",
      " FACE world\n",
      " The to Final the  女\n",
      "EYES-Of : [9-MKU9\n",
      " The thE DRAGON\n",
      "d \n",
      "luego of !\n",
      " A  & !?\n",
      "th-Movpfs>\n",
      "3121continue90\n",
      " 02 pF ll\n",
      "←KThe  ] ～二人の恋のテーマ～\n",
      "-T\n",
      "\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_23000\\assets\n",
      "\n",
      "\n",
      "epoch: 19, (24000)\n",
      "input: \t 進撃st20130629巨人\n",
      "pred: \t  st20130629巨人 \n",
      "\n",
      "5LiGHT-MIX\n",
      "\n",
      "13-5\n",
      "anglefool03\n",
      "into decide 2\n",
      "tings3\n",
      "MTheme2A-simpledessdonm)\n",
      " KT\n",
      "XORCiST <5 >\n",
      "4th-:罪\n",
      "/of-!?!\n",
      "ン怒&過多6-edit16］ : [size4theoff\n",
      ":過夕1guy\n",
      "-4100adlib\n",
      " ～me-SYNRM\n",
      "\n",
      "INFO:tensorflow:Assets written to: ./models/sawano_word_24000\\assets\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterations_per_batch = 10\n",
    "epochs = 20\n",
    "\n",
    "generated_tracks = {}\n",
    "\n",
    "for e in range(epochs*sample_size):\n",
    "    track_id = e % sample_size\n",
    "    x = X[track_id]\n",
    "    y = Y[track_id]\n",
    "    \n",
    "    x = x.reshape(-1, x.shape[0], x.shape[1])\n",
    "    y = y.reshape(-1, y.shape[0], y.shape[1])\n",
    "    \n",
    "    for i in range(iterations_per_batch):\n",
    "        model.train_on_batch(x, y)\n",
    "    \n",
    "    \n",
    "    if e % 1000 == 0:\n",
    "        epoch = e//sample_size\n",
    "        print(f\"epoch: {epoch}, ({e})\")\n",
    "        predicted = model.predict(x)\n",
    "        predicted = decode_prob_sentence(predicted[0], ix_to_word)\n",
    "        print(f\"input: \\t {tracklist[track_id]}\")\n",
    "        pred_output = ''.join(predicted)\n",
    "        pred_output = pred_output.replace('\\n', ' ')\n",
    "        print(f\"pred: \\t  {pred_output}\")\n",
    "        \n",
    "        num_track = 15\n",
    "        gen_tracks = []\n",
    "        for t in range(num_track):\n",
    "            gen_track = sampling(model, ix_to_word, n_x, max_word=25)\n",
    "            gen_tracks.append(gen_track)\n",
    "            print(\"\".join(gen_track[:-1]), end=\"\")\n",
    "        print(\"\\n\")\n",
    "        model.save(f\"./models/sawano_word_{e}\")\n",
    "        print(\"\\n\")\n",
    "        generated_tracks[e] = gen_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, tracks in generated_tracks.items():\n",
    "    with open(f\"./outputs/sawano_word_iteration_{k}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for track in tracks:\n",
    "            track_name = \"\".join(track[:-1])\n",
    "            f.writelines(track_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
